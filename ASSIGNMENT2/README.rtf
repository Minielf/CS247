{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 The bug I\'92ve run into is the runtime of my program is super slow that it may take longer than 10 mins at first. Then I figured out that I use m.optimizer() and m.accuracy_function() in the train and test steps and it takes a really long time to run. The right thing to do is to use the tensor of the computational graph in the class. \
\
The basic idea behind my program is that I use one hidden layer in the neural network. I have two sets of weights and bias, one is for input layer to hidden layer and the other is for hidden layer to the output layer. I use gradient descent optimizer to optimize the loss calculated.}